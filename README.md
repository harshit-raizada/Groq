# Groq

I have created a Q&A App using an open-source LLM Groq (mixtral-8x7b-32768) along with open-source embeddings (OllamaEmbeddings). I have sourced the data from an article of HCLTech which talks about GenAI. I have asked questions on the article and it is clearly giving correct answers. Although the answers are reliable and accurate but it's really time-consuming because of the Ollama Embeddings, I would recommend to use OpenAI Embeddings (Way faster).
