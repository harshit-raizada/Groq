# Groq

I have created a Q&A App using an open-source LLM Groq (mixtral-8x7b-32768) along with open-source embeddings (OllamaEmbeddings). Although the answers are reliable and accurate but it is really time-taking because of the Ollama Embeddings, I would recommend to use OpenAI Embeddings (Way faster).
